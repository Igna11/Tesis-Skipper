{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANALISIS DE DATOS DE IMÁGENES .fits\n",
    "\n",
    "## Análisis de los clústers\n",
    "\n",
    "la idea de este notebook es organizar la información del análisis de los clusters y descargar todo aquello que es redundante, como imágenes y código de prueba que puede encontrarse en el notebook ```Análisis_de_Imagenes.ipynb```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from astropy.io import fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage.measure\n",
    "from scipy import ndimage as ndi\n",
    "from scipy.stats import poisson\n",
    "import pandas as pd\n",
    "\n",
    "probabilidad = 0.2245\n",
    "\n",
    "import gc # Garbage collector: Para ayudar a mantener la RAM limpia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defino funciones bien básicas para el manejo de los datos y ajustes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regresion_lineal(X, Y):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : array like\n",
    "    Y : array like\n",
    "    returns: m y b de la linea mx + b\n",
    "    \"\"\"\n",
    "    N = len(X)\n",
    "    Delta = N*sum(X**2) - (sum(X))**2\n",
    "    m = (N*sum(X*Y) - sum(X)*sum(Y))/Delta\n",
    "    b = (sum(X**2)*sum(Y) - sum(X)*sum(X*Y))/Delta\n",
    "\n",
    "    return m, b\n",
    "\n",
    "def fits_finder(directorio=\".\", extension=\".fits\"):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    directorio : string, optional\n",
    "        The default is \".\"\n",
    "        El directorio \"madre\" del cual se quieren buscar las imágenes .png\n",
    "        de todos sus subdirectorios\n",
    "    extension : string, optional\n",
    "        The default is \".fits\"\n",
    "        La extensión del tipo de archivo que se quiere buscar en los\n",
    "        subdirectorios. Es necesario usar \".extension\": EJ: \".png\", \".jpg\"\n",
    "    Returns: string de directorios y archivos .png\n",
    "    \"\"\"\n",
    "    archivos = []\n",
    "    for root, dirs, files in os.walk(directorio):\n",
    "        for name in files:\n",
    "            path = os.path.join(root, name)\n",
    "            size = os.stat(path).st_size/1000\n",
    "            if path.endswith(extension) and size < 500:\n",
    "                archivos.append(path)\n",
    "    return archivos\n",
    "\n",
    "\n",
    "def ADU2e(src_path, \n",
    "          alpha=1.9848e-3, \n",
    "          beta=-9.77376e-11, \n",
    "          gamma=1.87747e-15,\n",
    "          delta=-7.08404e-21,\n",
    "          ohdu=0, save=False):\n",
    "    \"\"\"\n",
    "\n",
    "    From a .fits image, and using the polynomial fit for ADU -> electron\n",
    "    returns both image data:\n",
    "        image in ADU's\n",
    "        image in e- units.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    src_path : string\n",
    "        Directory path of the file\n",
    "    alpha : float, optional\n",
    "        By default, alpha = 1.9848e-3\n",
    "        ref: ske_Calibration_T123k.txt\n",
    "        ref: Tesis Kevin Anderson, tabla 3.1: alpha = 1.99e-3\n",
    "    beta : float, optional\n",
    "        By default, beta = -9.77376e-11\n",
    "        ref: ske_Calibration_T123k.txt\n",
    "        ref: Tesis Kevin Anderson, tabla 3.1: beta = 8.61e-11\n",
    "    gamma : float, optional\n",
    "        By default, beta = 1.87747e-15\n",
    "        ref: ske_Calibration_T123k.txt\n",
    "        ref: Tesis Kevin Anderson, tabla 3.1: gamma = -6.31e-17\n",
    "    delta : float, optional\n",
    "        By default, beta = -7.08404e-21\n",
    "        ref: ske_Calibration_T123k.txt\n",
    "        ref: Tesis Kevin Anderson, tabla 3.1: delta = 2.73e-23\n",
    "        the values used here differ from the ones in the Kevin Anderson's tesis\n",
    "    ohdu : int, optional\n",
    "        0, 1, 2, 3 allowed (each sensor of the total sensor)\n",
    "    save : bool, optional\n",
    "        When set True, a new fits file in electron units is saved\n",
    "    \"\"\"\n",
    "    with fits.open(src_path) as fits_img:\n",
    "        ADU_img_data = fits_img[ohdu].data\n",
    "        e_img_data = np.round(ADU_img_data*alpha \n",
    "                              + ADU_img_data**2*beta\n",
    "                              + ADU_img_data**3*gamma\n",
    "                              + ADU_img_data**4*delta)\n",
    "        # =====================================\n",
    "        # Los datos vienen con valores negativos:\n",
    "        # filtro los valores negativos y los transformo en 0\n",
    "        ADU_img_data[ADU_img_data < 0] = 0\n",
    "        e_img_data[e_img_data < 0] = 0\n",
    "\n",
    "        if save is True:\n",
    "            fits_img[ohdu].data = e_img_data\n",
    "            tgt_path = src_path.strip(\".fits\") + \"electron_units.fits\"\n",
    "            fits_img.writeto(tgt_path)\n",
    "    return e_img_data, ADU_img_data\n",
    "\n",
    "\n",
    "def single_fits2double_fits(src_path, tgt_path=\"\", threshold=1, ohdu=0,\n",
    "                            save=False):\n",
    "    \"\"\"\n",
    "\n",
    "    From one .fits file generates 2 new fits files.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    src_path : string\n",
    "        Path to the original .fits file or filename\n",
    "    tgt_path : string\n",
    "        path to the 2 new .fits files or filename WITHOUT EXTENSION.\n",
    "        e.g /media/usr/.../image_name <-- correct\n",
    "        e.g /media/usr/.../image_name.fits <-- incorrect\n",
    "    threshold : int, optional\n",
    "        Threshold to start counting electrons. The data will be divided into\n",
    "        two diferents arrays, one with all pixels having a number of electrons\n",
    "        greater than threshold and the other one having the rest.\n",
    "        The default is 1.\n",
    "    ohdu : int, optional.\n",
    "        0,1,2,3 allowed (each sensor of the total sensor)\n",
    "    save : bool, optional.\n",
    "        If set True, then generates the 2 .fits files with the threshold\n",
    "        applied\n",
    "    Returns\n",
    "    -------\n",
    "    None.\n",
    "\n",
    "    \"\"\"\n",
    "    electron_fits = ADU2e(src_path, ohdu=ohdu)[0]\n",
    "\n",
    "    # make some copies of the original data to modify it avoiding aliasing\n",
    "    elec_minor = electron_fits.copy()\n",
    "    elec_major = electron_fits.copy()\n",
    "\n",
    "    # All pixels with a number of electrons > threshold are set to 0\n",
    "    elec_minor[elec_minor > threshold] = 0\n",
    "    # All pixels with a number of electrons < threshold are set to 0\n",
    "    elec_major[elec_major <= threshold] = 0\n",
    "\n",
    "    # differenciate the minor and major paths\n",
    "    tgt_path_minor = tgt_path + \"minor.fits\"\n",
    "    tgt_path_major = tgt_path + \"major.fits\"\n",
    "    if save is True:\n",
    "        with fits.open(src_path) as fits_img:\n",
    "            # save elec_minor\n",
    "            fits_img[ohdu].data = elec_minor\n",
    "            try:\n",
    "                fits_img.writeto(tgt_path_minor)\n",
    "            except OSError as e:\n",
    "                print(e)\n",
    "                print(\"A file with the same name already exists.\")\n",
    "            # save elec_major\n",
    "            fits_img[ohdu].data = elec_major\n",
    "            try:\n",
    "                fits_img.writeto(tgt_path_major)\n",
    "            except OSError as e:\n",
    "                print(e)\n",
    "                print(\"A file with the same name already exists.\")\n",
    "    return elec_minor, elec_major"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defino las funciones que trabajan con los datos de las imágenes, clusterizando y extrayendo la información de los clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "author: Santiago Ezequiel Perez\n",
    "Quien amablemente me pasó estas funciones para usarlas\n",
    "\"\"\"\n",
    "\n",
    "def get_cluster_info(image, labels):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    image : numpy array\n",
    "        Array de numpy con los datos de la imagen\n",
    "    labels : numpy array\n",
    "        Array de numpy de la misma estructura dimensional que el array\n",
    "        imagen. Contiene 0 donde no hay features y contiene enteros \n",
    "        crecientes para etiquetar (labelear) los features.\n",
    "    ----------\n",
    "    Returns: dict\n",
    "        Diccionario con las siguientes keys:\n",
    "            areas,\n",
    "            centros,\n",
    "            coordenadas,\n",
    "            perimetro,\n",
    "            energias,\n",
    "            box\n",
    "    \"\"\"\n",
    "    def image_intensity(region, intensities):\n",
    "        \"\"\"\n",
    "        Es una función interna de get_cluster_info\n",
    "        Suma las intensidades de una region en unidades de electrones\n",
    "        \"\"\"\n",
    "        return np.sum(intensities[region])\n",
    "\n",
    "    rps = skimage.measure.regionprops(labels,\n",
    "                                      intensity_image=image,\n",
    "                                      cache=False,\n",
    "                                      extra_properties=[image_intensity])\n",
    "    areas = [r.area for r in rps]\n",
    "    energy = [r.image_intensity for r in rps]\n",
    "    centros = [r.centroid for r in rps]\n",
    "    coords = [r.coords for r in rps]\n",
    "    perimetro = [r.perimeter for r in rps]\n",
    "    \n",
    "    dic_props = {\"areas\": areas,\n",
    "                 \"centros\": centros,\n",
    "                 \"coordenadas\": coords,\n",
    "                 \"perimetro\": perimetro,\n",
    "                 \"energias\": energy}\n",
    "    return dic_props\n",
    "\n",
    "def img2bw(image, lower_thresh=None, upper_thresh=None):\n",
    "    \"\"\"\n",
    "    Binariza la imagen ingresada según el threshold dado:\n",
    "    Parameters\n",
    "    ----------\n",
    "    image : numpy array\n",
    "        Array de numpy con los datos de la imagen\n",
    "    lowel_trhesh : int - float, optional\n",
    "        threshold minimo para el binarizado de la imagen.\n",
    "        Si nada es ingresado, entonces se toma como nulo\n",
    "    upper_trhesh : int - float, optional\n",
    "        threshold máximo para el binarizado de la imagen.\n",
    "        Si nada es ingresado, entonces se toma como nulo\n",
    "    ----------\n",
    "    Returns: numpy array of bools\n",
    "        array de numpy con la misma dimensionalidad que el\n",
    "        input, pero con todos valores booleanos.\n",
    "    \"\"\"\n",
    "    if lower_thresh is None:\n",
    "        lower_thresh = 0\n",
    "    if upper_thresh is None:\n",
    "        upper_thresh = np.max(image) + 1\n",
    "    return (image >= lower_thresh) & (image <= upper_thresh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guardo en lista todo los directorios de las imágenes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR = \"/home/igna/Escritorio/Tesis2021/Archivos/T123K\"\n",
    "os.chdir(DIR)\n",
    "fits_imgs_list = fits_finder(DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### El procedimiento para reconocer clústers sería el siguiente:\n",
    "- Me genero el array de numpy que contiene la data de la imagen fits con ```ADU2e```.\n",
    "- Binarizo la imagen usando ```img2bw``` y la guardo en una nueva variable con sufijo ```_bw```. La imagen binarizada es un array de True's y False's. Se pierde la información de intesidades.\n",
    "- Me armo mis \"features labels\" usando ```ndi.label``` dándole de comer a esa funcion la imagen binarizada a partir del threshold dado.\n",
    "- El argumento ```structure``` de ```ndi.label``` define la forma en la que se conectan los features (en mi caso clusters)\n",
    "- Con ```get_cluster_info``` (que ya la modifiqué para que me de más propiedades) obtengo la información de los \"features\" que ndi encontró, en este caso los clusters. El input es el array de numpy con la información de la imagen y los labels que escupe ```ndi.labels```. El output es un diccionario con las siguientes keys: \n",
    "    - areas\n",
    "    - centros\n",
    "    - coordenadas\n",
    "    - perimetro\n",
    "    - energias\n",
    "    - box\n",
    "- ploteo la imagen y marco con círculos los clusters que reconoció (opcional - acá no)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este procedimiento lo voy a aplicar tanto a imagenes originales como a imágenes a las que les voy a agregar ruido sintéticamente utilizando el valor $\\mu$ calculado en ```Analisis_imagenes_probabilidad.ipynb``` que es\n",
    "$\\mu = 0.2235 \\pm 0.0001$\n",
    "\n",
    "Voy a trabajar con 3 DataFrames diferentes:\n",
    "- df_o (df_original) para la información de los clusters detectados en las imágenes originales\n",
    "- df_l (df_labeled) para la información de los clusters de las imágenes con ruido simulado, usando labels originales\n",
    "- df_s (df_simulated) para la información de los nuevos clústers al agregar ruido simulado a las imágenes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defino 2 funciones: ```image2cluster_info``` y ```df_gen```. La primera extrae toda la información de las imágenes, ya sea originales o simuladas y devuelve 3 listas con la información necesaria para pasarle a df_gen para armar los DataFrames correspondientes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=============================================================================\n",
    "\n",
    "def image2cluster_info(fits_imgs_list, low_th=2, upp_th=300, ohdu=0, img=\"o\"):\n",
    "    \"\"\"\n",
    "    Extrae la información de los clusters de todas las imágenes y lo guarda en\n",
    "    listas\n",
    "    Parameters\n",
    "    ----------\n",
    "    fits_imgs_list : list\n",
    "        lista de directorios donde están las imágenes .fits\n",
    "    img : str - optional\n",
    "        para indicarle si va a buscar clusters:\n",
    "            \"o\": Busca los features en la imagen original.\n",
    "            \"l\": Busca los features en la imagen simulada, pero usa los labels\n",
    "            para de la imagen original.\n",
    "            \"s\": Busca los features de la iamgen simulada.\n",
    "    low_th : int - optional\n",
    "        lower detection threshold\n",
    "    upp_th : int - optional\n",
    "        Upper detection threshold\n",
    "    ohdu : int - optional\n",
    "        The HDU data: 0, 1, 2, 3 available\n",
    "    ----------\n",
    "    Returns: lista_dics, lista_b_features, lista_img_idxs\n",
    "        lista con la información\n",
    "    \"\"\"\n",
    "    \n",
    "    # Armo listas donde guardo la info\n",
    "    lista_dics = []\n",
    "    lista_n_features = []\n",
    "    lista_img_idxs = []\n",
    "    \n",
    "    # Hardcodeo el mu de la poissoniana\n",
    "    mu = 0.2243\n",
    "\n",
    "    # recorro las imagenes que quiero usar\n",
    "    for i, image in enumerate(fits_imgs_list):\n",
    "        # Imagen completa\n",
    "        image_o = ADU2e(image, ohdu=ohdu)[0]\n",
    "        \n",
    "        # Imagen con clústers unicamente\n",
    "        image_s = single_fits2double_fits(image, ohdu=ohdu)[1]\n",
    "        # Le agrego ruido a la imagen con clusters unicamente\n",
    "        image_s += poisson.rvs(mu, size=(50, 493))\n",
    "\n",
    "        # Binarizo ambas imagenes:\n",
    "        image_o_bw = img2bw(image_o, lower_thresh=low_th, upper_thresh=upp_th)\n",
    "        image_s_bw = img2bw(image_s, lower_thresh=low_th, upper_thresh=upp_th)\n",
    "\n",
    "        # Genero las labels y también guardo el número de features\n",
    "        label_im_o, n_features_o = ndi.label(image_o_bw,\n",
    "                                             structure=[[1, 1, 1],\n",
    "                                                        [1, 1, 1],\n",
    "                                                        [1, 1, 1]])\n",
    "        label_im_s, n_features_s = ndi.label(image_s_bw,\n",
    "                                             structure=[[1, 1, 1],\n",
    "                                                        [1, 1, 1],\n",
    "                                                        [1, 1, 1]])\n",
    "\n",
    "        # Armo el diccionario con información que devuelve get_cluster_size_etc\n",
    "        if img == \"o\":\n",
    "            dic = get_cluster_info(image_o, label_im_o)\n",
    "            n_features = n_features_o\n",
    "        elif img == \"l\":\n",
    "            dic = get_cluster_info(image_s, label_im_o)\n",
    "            n_features = n_features_o\n",
    "        elif img == \"s\":\n",
    "            dic = get_cluster_info(image_s, label_im_s)\n",
    "            n_features = n_features_s\n",
    "        else:\n",
    "            print(\"opción incorrecta: Solo 'o', 'l', 's' son válidos\")\n",
    "            return 0\n",
    "        lista_dics.append(dic)\n",
    "        lista_n_features.append(n_features)\n",
    "        lista_img_idxs.append(np.ones(n_features)*i)\n",
    "        # Printeo el progreso del ciclo for\n",
    "        print(\"\\r%.2f%%\" % (100*(i+1)/925), end = \"\")\n",
    "    \n",
    "    return lista_dics, lista_img_idxs\n",
    "\n",
    "\n",
    "def df_gen(lista_dics, lista_img_idxs):\n",
    "    \"\"\"\n",
    "    Esta función arma a partir de la listas de información un DataFrame de \n",
    "    pandas para manipular la información más comodamente\n",
    "    Parameters\n",
    "    ----------\n",
    "    lista_dics : list\n",
    "        lista de diccionarios\n",
    "    lista_img_idxs : list\n",
    "        lista de índices para identificar una misma imagen\n",
    "    ----------\n",
    "    Returns: pd.DataFrame\n",
    "        DataFrame con toda la información de las imágenes\n",
    "    \"\"\"\n",
    "    \n",
    "    # armo listas para meter los datos\n",
    "    energias = []\n",
    "    areas = []\n",
    "    centros = []\n",
    "    perimetros = []\n",
    "    \n",
    "    # meto los datos en las listas\n",
    "    for dics in lista_dics:\n",
    "        energias += dics[\"energias\"]\n",
    "        areas += dics[\"areas\"]\n",
    "        centros += dics[\"centros\"]\n",
    "        perimetros += dics[\"perimetro\"]\n",
    "        \n",
    "    # concateno los índices para que sea un solo array\n",
    "    lista_img_idxs = np.concatenate(lista_img_idxs)\n",
    "    \n",
    "    # Armo el dicionario\n",
    "    diccionario = {}\n",
    "    diccionario[\"img_idx\"] = lista_img_idxs\n",
    "    diccionario[\"energia\"] = energias\n",
    "    diccionario[\"area\"] = areas\n",
    "    diccionario[\"centro\"] = centros\n",
    "    diccionario[\"perimetro\"] = perimetros\n",
    "    \n",
    "    return pd.DataFrame.from_dict(diccionario)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si tengo hechos los archivos, los abro como DataFrames. Si no, empiezo a buscar clusters con el algoritmo en las imagenes originales (puede tardar unos minutos) y los transformo a DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.00%\n",
      "Listo las originales!\n",
      "\n",
      "100.00%\n",
      "Listo las 'medio' simuladas!\n",
      "\n",
      "100.00%\n",
      "Listo las simuladas!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#=============================================================================\n",
    "# PARA CARGAR LOS DATOS SIN CORRERLOS CADA VEZ\n",
    "os.chdir(\"/media/igna/ignag/Igna/Facultad/Tesis2021/AnalisisImagenesFits/\")\n",
    "\n",
    "# LA CARPETA DONDE TENGO DATOS DE UNA U OTRA CALIBRACIÓN\n",
    "carpeta = \"Data_Calibracion_Nueva\"\n",
    "#carpeta = \"Data_Calibracion_Vieja\"\n",
    "\n",
    "\n",
    "# REESCRIBO O NO?\n",
    "reescribir = True\n",
    "\n",
    "# Si los archivos existen en el directorio, los cargo\n",
    "if (\"data_original.csv\" in os.listdir(carpeta)\n",
    "    and \"data_l_original.csv\" in os.listdir(carpeta)\n",
    "    and \"data_sim.csv\" in os.listdir(carpeta)\n",
    "    and reescribir is False):\n",
    "    os.chdir(carpeta)\n",
    "    usecols=[\"img_idx\", \"energia\", \"area\", \"centro\", \"perimetro\"]\n",
    "    df_o = pd.read_csv(\"data_original.csv\", sep=\"\\t\", usecols=usecols)\n",
    "    df_l = pd.read_csv(\"data_l_original.csv\", sep=\"\\t\", usecols=usecols)\n",
    "    df_s = pd.read_csv(\"data_sim.csv\", sep=\"\\t\", usecols=usecols)\n",
    "\n",
    "# Si no, los genero (pero puede tardar un rato) y armo los DataFrame\n",
    "elif reescribir is True:\n",
    "    # ME VOY A LA CARPETA DONDE QUIERO GUARDAR LOS DATOS\n",
    "    os.chdir(carpeta)\n",
    "    # datos de las imagenes originales\n",
    "    lista_dics_o, lista_img_idx_o = image2cluster_info(fits_imgs_list,\n",
    "                                                       img=\"o\",\n",
    "                                                       upp_th=None)\n",
    "    print(\"\\nListo las originales!\\n\")\n",
    "    # datos de imágenes simuladas pero usando los labels de la original\n",
    "    lista_dics_l, lista_img_idx_l = image2cluster_info(fits_imgs_list,\n",
    "                                                       img=\"l\",\n",
    "                                                       upp_th=None)\n",
    "    print(\"\\nListo las 'medio' simuladas!\\n\")\n",
    "    # datos de imágenes simuladas 100%\n",
    "    lista_dics_s, lista_img_idx_s = image2cluster_info(fits_imgs_list,\n",
    "                                                       img=\"s\",\n",
    "                                                       upp_th=None)\n",
    "    print(\"\\nListo las simuladas!\\n\")\n",
    "    \n",
    "    # originales\n",
    "    df_o = df_gen(lista_dics_o, lista_img_idx_o)\n",
    "    df_o.to_csv(\"data_original.csv\", sep=\"\\t\")\n",
    "    # simulados con labels originales\n",
    "    df_l = df_gen(lista_dics_l, lista_img_idx_l)\n",
    "    df_l.to_csv(\"Data_data_l_original.csv\", sep=\"\\t\")\n",
    "    # 100% simulados\n",
    "    df_s = df_gen(lista_dics_s, lista_img_idx_s)\n",
    "    df_s.to_csv(\"data_sim.csv\", sep=\"\\t\")\n",
    "    # Borro lo que ya no me interesa tener\n",
    "    del (lista_dics_o, lista_img_idx_o, lista_dics_l, lista_img_idx_l,\n",
    "         lista_dics_s, lista_img_idx_s)\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a)De acá hasta (b) estoy probando cosas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(462597, 462597)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_o), len(df_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_diff_ol' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-d5a331af622d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_diff_ol\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_diff_ol\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"energia\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m160\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdf_diff_ol\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"energia\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df_diff_ol' is not defined"
     ]
    }
   ],
   "source": [
    "df_diff_ol[(df_diff_ol[\"energia\"]>160) & (df_diff_ol[\"energia\"]<200)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_l[(df_l[\"energia\"]>160) & (df_l[\"energia\"]<200)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_o[(df_o[\"energia\"]>160) & (df_o[\"energia\"]<200)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creo un DataFrame para las diferencias entre originales y medio simuladas\n",
    "df_diff_ol = df_o.copy()\n",
    "df_diff_ol[\"diff_e\"] = abs(df_o[\"energia\"]-df_l[\"energia\"])\n",
    "df_diff_ol[\"diff_area\"] = abs(df_o[\"area\"]-df_l[\"area\"])\n",
    "df_diff_ol.set_index(\"img_idx\", inplace=True)\n",
    "#df_diff_ol.drop([\"Unnamed: 0\"], axis=1, inplace=True)\n",
    "df_diff_ol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) fin de pruebas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=============================================================================\n",
    "# Ahora inteto matchear eventos de mismas imágenes\n",
    "#\n",
    "df_diff_os = pd.DataFrame()\n",
    "Diff_e = pd.DataFrame()\n",
    "Diff_area = pd.DataFrame()\n",
    "Diff_perimetro = pd.DataFrame()\n",
    "\n",
    "index = np.arange(0, 925, 1)\n",
    "\n",
    "for idx in index:\n",
    "\n",
    "    df_aux_o = df_o[df_o[\"img_idx\"] == idx]\n",
    "    df_aux_s = df_s[df_s[\"img_idx\"] == idx]\n",
    "    \n",
    "    df_coincidente_o = df_aux_o.loc[df_aux_o[\"centro\"]\n",
    "                                    .isin(df_aux_s[\"centro\"])].copy()\n",
    "    df_coincidente_s = df_aux_s.loc[df_aux_s[\"centro\"]\n",
    "                                    .isin(df_aux_o[\"centro\"])].copy()\n",
    "    \n",
    "    df_coincidente_o.reset_index(inplace=True)\n",
    "    df_coincidente_s.reset_index(inplace=True)\n",
    "    \n",
    "    df_coincidente_o.set_index(\"img_idx\", inplace=True)\n",
    "    df_coincidente_s.set_index(\"img_idx\", inplace=True)\n",
    "    \n",
    "    #df_coincidente_o.drop([\"Unnamed: 0\", \"index\"], axis=1, inplace=True)\n",
    "    #df_coincidente_s.drop([\"Unnamed: 0\", \"index\"], axis=1, inplace=True)\n",
    "    \n",
    "    df_diff_os = df_diff_os.append(df_coincidente_o.copy())\n",
    "    \n",
    "    diff_e = df_coincidente_o[[\"energia\"]] - df_coincidente_s[[\"energia\"]]\n",
    "    diff_area = df_coincidente_o[[\"area\"]] - df_coincidente_s[[\"area\"]]\n",
    "    diff_perimetro = df_coincidente_o[[\"perimetro\"]] - df_coincidente_s[[\"perimetro\"]]\n",
    "    \n",
    "    Diff_e = Diff_e.append(abs(diff_e))\n",
    "    Diff_area = Diff_area.append(abs(diff_area))\n",
    "    Diff_perimetro = Diff_perimetro.append(abs(diff_perimetro))\n",
    "    print(\"\\r%.2f%%\" % (idx*100/924), end=\" \")\n",
    "\n",
    "df_diff_os[\"diff_e\"] = Diff_e\n",
    "df_diff_os[\"diff_area\"] = Diff_area\n",
    "df_diff_os[\"diff_perimetro\"] = Diff_perimetro\n",
    "del Diff_e, Diff_area, Diff_perimetro\n",
    "gc.collect() # Tira la basura que queda en la memoria\n",
    "df_diff_os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por último, tanto a ```df_diff_ol``` y ```df_diff_os``` voy a agregarles dos columnas: \n",
    "- Una para la esperanza de la cantidad de carga por cluster (en función del área) para una distribución binomial de la cantidad de eventos por píxel.\n",
    "- Otra para la esperanza de la cantidad de carga por cluster (en función del área) para una distribución poissoniana de la cantidad de eventos por píxel.\n",
    "\n",
    "La esperanza de una Binomial viene dada simplemente por \n",
    "\\begin{equation}\n",
    "    E(k) = np\n",
    "\\end{equation}\n",
    "\n",
    "donde $n$ es el número de píxeles y $p$ es la probabilidad de que haya una carga en el píxel.\n",
    "\n",
    "La esperanza de la Poisson en función de la cantidad de píxeles la calculo de la siguiente manera: Si $\\mu$ es la esperanza de la Poissoniana para un dado píxel, entonces si $k$, variable aleatoria con distribución Poissoniana, es el número de electrones espurios por píxel, la esperanza de la variable aleatoria $k$ viene dada por $E(k) = \\mu$. Pero para un clúster de $N$ píxeles, el número de electrones espurios por clúster será\n",
    "\n",
    "$$ n = \\sum\\limits_{i=1}^{N}k_{i}$$\n",
    "\n",
    "donde $k_{i}$ es la cantidad de electrones espurios en el píxel $i$-ésimo y $N$ es la cantidad de píxeles del cluster. Entonces, quiero calcular la esperanza de $n$, $E(n)$, y como la esperanza de la suma es la suma de las esperanzas, se tiene\n",
    "\n",
    "$$E(n) = E\\left( \\sum\\limits_{i=1}^{N} k_{i}\\right) = \\sum\\limits_{i=1}^{N}E(k_{i})$$\n",
    "\n",
    "como la esperanza de la distribución es la misma, para cualquier $k_{i}$ es el mismo $\\mu$, entonces\n",
    "\n",
    "$$E(n) = \\mu \\sum\\limits_{i=1}^{N} 1 = N \\mu,$$\n",
    "\n",
    "Entonces, la esperanza de la variable aleatoria **número de electrones espurios en un cluster** viene dada por $N\\mu$, muy parecida a la binomial.\n",
    "\n",
    "Como $p$ y $\\mu$ son lo mismo, entonces ambas esperanzas son las mismas! Entonces no agrego dos columnas, agrego una sola que se llama esperanza."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_diff_ol[\"esperanza\"] = df_diff_ol[\"area\"]*probabilidad\n",
    "df_diff_os[\"esperanza\"] = df_diff_os[\"area\"]*probabilidad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ya tengo el dataframe con la info que necesito para los clusters con ruido agregado usando labels originales y clusters con ruido agregado usando nuevos labels. El análisis que quiero hacer ahora es, para el rango $160$ a $200$ electrones de carga total (columna ```\"energia\"```), ver las diferencias y poder estimar el sesgo que agregan al conteo de la carga total de los clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_diff_ol[(df_diff_ol[\"energia\"]>160) & (df_diff_ol[\"energia\"]<200)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_diff_os[(df_diff_os[\"energia\"]>160) & (df_diff_os[\"energia\"]<200)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Histogramas de carga para cada dataset\n",
    "#### original\n",
    "#### simulado y labels originales\n",
    "#### simulado 100%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "energia_o = df_o[(df_o[\"energia\"]>100) & (df_o[\"energia\"]<300)][\"energia\"]\n",
    "energia_l = df_l[(df_l[\"energia\"]>100) & (df_l[\"energia\"]<300)][\"energia\"]\n",
    "energia_s = df_s[(df_s[\"energia\"]>100) & (df_s[\"energia\"]<300)][\"energia\"]\n",
    "\n",
    "fig, axs = plt.subplots(3,1, figsize=(17,12))\n",
    "\n",
    "axs[0].set_title(\"Distribución de carga original\")\n",
    "axs[0].hist(energia_o, bins=250, fill=False)\n",
    "axs[0].set_yscale(\"log\")\n",
    "axs[1].set_title(\"Distribución de simulada con labels originales\")\n",
    "axs[1].hist(energia_l, bins=250, fill=False)\n",
    "axs[1].set_yscale(\"log\")\n",
    "axs[2].set_title(\"Distribución de simulada\")\n",
    "axs[2].hist(energia_s, bins=250, fill=False);\n",
    "axs[2].set_yscale(\"log\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparación entre datos medidos, simulaciones y teórico\n",
    "### Caso simulado con labels originales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# nuevo DataFrame\n",
    "DF_ol = df_diff_ol[[\"area\", \"diff_e\", \"esperanza\"]].groupby(\"area\").mean()\n",
    "DF_ol[\"error\"] = df_diff_ol[[\"area\", \"diff_e\"]].groupby(\"area\").std()\n",
    "# reseteo el índice \n",
    "DF_ol.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hago el ajuste\n",
    "m, b = regresion_lineal(DF_ol[\"area\"].head(50), DF_ol[\"diff_e\"].head(50))\n",
    "\n",
    "\n",
    "plt.figure(figsize=(17, 3))\n",
    "# ploteo el ajuste\n",
    "plt.plot(DF_ol[\"area\"].head(50), DF_ol[\"area\"].head(50)*m + b, \n",
    "         color=\"#E69F00\",\n",
    "         linewidth=3,label=\"$f(x)=%.3f + %.3f$\" % (m, b))\n",
    "\n",
    "# ploteo los datos promediados\n",
    "plt.plot(DF_ol[\"area\"].head(50), DF_ol[\"diff_e\"].head(50),\n",
    "         'o',\n",
    "         color=\"#56B4E9\", \n",
    "         markersize=8,\n",
    "         label=\"Medido\")\n",
    "\n",
    "# ploteo la teórica (binomial) con circulos abiertos\n",
    "plt.plot(DF_ol[\"area\"].head(50), DF_ol[\"esperanza\"].head(50),\n",
    "         'o',\n",
    "         color=\"k\",\n",
    "         markersize=12,\n",
    "         fillstyle=\"none\",\n",
    "         label=\"analítico\")\n",
    "plt.legend(fontsize=18);\n",
    "#plt.savefig(\"BinomialVSMontecarlo.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Caso 100% simulado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# nuevo DataFrame\n",
    "DF_os = df_diff_os[[\"area\", \"diff_e\", \"esperanza\"]].groupby(\"area\").mean()\n",
    "DF_os[\"error\"] = df_diff_os[[\"area\", \"diff_e\"]].groupby(\"area\").std()\n",
    "# reseteo el índice \n",
    "DF_os.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hago el ajuste\n",
    "m, b = regresion_lineal(DF_os[\"area\"].head(50), DF_os[\"diff_e\"].head(50))\n",
    "\n",
    "\n",
    "plt.figure(figsize=(17, 3))\n",
    "# ploteo el ajuste\n",
    "plt.plot(DF_os[\"area\"].head(50), DF_os[\"area\"].head(50)*m + b, \n",
    "         color=\"#E69F00\",\n",
    "         linewidth=3,label=\"$f(x)=%.3f + %.3f$\" % (m, b))\n",
    "\n",
    "# ploteo los datos promediados\n",
    "plt.plot(DF_os[\"area\"].head(50), DF_os[\"diff_e\"].head(50),\n",
    "         'o',\n",
    "         color=\"#56B4E9\", \n",
    "         markersize=8,\n",
    "         label=\"Medido\")\n",
    "\n",
    "# ploteo la teórica (binomial) con circulos abiertos\n",
    "plt.plot(DF_os[\"area\"].head(50), DF_os[\"esperanza\"].head(50),\n",
    "         'o',\n",
    "         color=\"k\",\n",
    "         markersize=12,\n",
    "         fillstyle=\"none\",\n",
    "         label=\"analítico\")\n",
    "plt.legend(fontsize=18);\n",
    "#plt.savefig(\"BinomialVSMontecarlo.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3,1, figsize=(17,12))\n",
    "\n",
    "axs[0].set_title(\"Distribución de áreas de clusters con menos de 300 electrones (originales)\")\n",
    "axs[0].hist(df_o[df_o[\"energia\"]<250][\"area\"], bins=80, density=True, fill=False)\n",
    "axs[0].set_yscale(\"log\")\n",
    "axs[0].grid(alpha=.5)\n",
    "\n",
    "axs[1].set_title(\"Distribución de variaciones en el perímetro de los clusters\")\n",
    "axs[1].hist(df_diff_os[\"diff_perimetro\"], bins=80, density=True, fill=False)\n",
    "axs[1].set_yscale(\"log\")\n",
    "axs[1].grid(alpha=.5)\n",
    "\n",
    "\n",
    "axs[2].set_title(\"Distribución de variaciones en el área de los clusters\")\n",
    "axs[2].hist(df_diff_os[\"diff_area\"], bins=80, density=True, fill=False)\n",
    "axs[2].set_yscale(\"log\")\n",
    "axs[2].grid(alpha=.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Promedio de eventos entre 160 y 220 por imagen\n",
    "eventosF_p_img = len(df_o[(df_o[\"energia\"]>160) & (df_o[\"energia\"]<220)])/925\n",
    "eventosF_tot = len(df_o[(df_o[\"energia\"]>160) & (df_o[\"energia\"]<220)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Promedio de eventos entre 1400 y 1600 por imagen\n",
    "eventosFE_p_img = len(df_o[(df_o[\"energia\"]>1400) & (df_o[\"energia\"]<1600)])/925\n",
    "eventosFE_tot = len(df_o[(df_o[\"energia\"]>1400) & (df_o[\"energia\"]<1600)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"eventos de F totales: {eventosF_tot}\")\n",
    "print(f\"eventos de F por imagen: {eventosF_p_img:.2f}\")\n",
    "print(f\"eventos de Fe totales: {eventosFE_tot}\")\n",
    "print(f\"eventos de Fe por imagen: {eventosFE_p_img:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_o"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
